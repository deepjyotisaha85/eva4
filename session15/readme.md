# EVA4 15 : Mask & Depth Prediction

#### Submitted By #### 
Deepjyoti Saha
Canvas ID: deepjyoti.saha@gmail.com

## Overview
Till now, I have been playing with classification problems, which predict classes in a given image. In this exercise I have built a DNN which predicts images! This network takes two input images - an image with a foreground object & a background scene, and an image with only the background scene, and generates the mask for the foreground object and a depthmap of the image. How cool is that!

### Usage
```python

from utils import predict

## modelpath = <Absolute Path for Model File>
## filepath = <Absolute Path for Test Image Files>
## bg = <Filename for Background Image>
## image = <Filename for Image>

predict.predict_images(modelpath, filepath, bg,  image)
```

### Input & Output Images ###
The results were generated with input images that network has never seen.

|    Background (Input)     |     Image (Input).    |    Predicted Mask (Output).  | Predicted Depthmap (Output) |
| ---------------- | ---------------- | -------------- | ------------------ |
| <img src="assets/bg1.png" width="150" >  |  <img src="assets/img1.png" width="150" > |  <img src="assets/mask1.png" width="150" > |  <img src="assets/depthmap1.png" width="150" > |
| <img src="assets/bg2.png" width="150" >  |  <img src="assets/img2.png" width="150" > |  <img src="assets/mask2.png" width="150" > |  <img src="assets/depthmap2.png" width="150" > |
| <img src="assets/bg1.png" width="150" >  |  <img src="assets/img1.png" width="150" > |  <img src="assets/mask1.png" width="150" > |  <img src="assets/depthmap1.png" width="150" > |
| <img src="assets/bg2.png" width="150" >  |  <img src="assets/img2.png" width="150" > |  <img src="assets/mask2.png" width="150" > |  <img src="assets/depthmap2.png" width="150" > |

### Model



## Solution

### Problem Statement
In this exercise I attempted to build DNN which takes two input images - an image with a foreground object & a background scene, and an image with only the background scene, and generates the mask for the foreground object and a depthmap of the image.

### Approach
The approach is to build a DNN using ideas from the RESNET architecture, and then design the tail to predict output images instead of labels. I have then used suitable loss functions to train the network to learn the patterns and predict the mask and depthmap images. I have used two different heads and different loss functions for the mask and depthmap prediction. 

### Dataset 
The dataset consists of the following images sets: </br>
* Background Images: These are images of a scene, in this case a park. 
* Foreground Images: These are images of an object, in this case a dog with a transparent background.
* Foreground Mask Images:These are the mask images of the foreground image. 
* Generated Images: These are images generated by superimposing the object on the scene, i.e, the dog on the park. For each foreground and background combination, the foreground images is superimposed at 20 random positions, and again flipped superimposed at 20 random postitions. 
* Mask for Generated Images: This is the mask for generated images. 
* Depthmap Images: These are the depthmap images of the generated image, these are generated using a DepthDepth model. 

The dataset consist of 400000 images for each set.

More details on the dataset can be found here: [Session 15A - Dataset Generation](https://github.com/deepjyotisaha85/eva4/tree/master/session15A)

### Data Pipeline
The key challenge in setting up the datapipeline was the sheer volume of data. Each of the image set to be processed had 400000 image files. I built a customer Dataset class which extends the Dataset class from Pytorch and I read the files directly from the filesystem in the __getitem__. This is because the data volume was too large to be read and stored in a single shot.

Further, I converted the mask images to grayscale to further optimize, as the information contained there is monochrome. I did not intentionally convert the background and image to grayscale hoping that colour information would help down the line.

Finally I converted the images to 64 x 64 for training, as beyond that resolution I was not able to train it on Colab using the available hardware resources. The original image sizes were 220 x 220.

### Model
The network has 2 different tasks to perform - predict the masks and predict the depthmaps. I have used two different loss functions for these tasks. However, on training I found that mask was getting trained more easily than the depth map, hence I decided to conider a weighted average of the two loss functions, so that I can assign weights to each.


### Loss Function

#### Loss Function for Mask

#### Loss Function for Depthmap

### Evaluation 


### Training

## Next Steps

